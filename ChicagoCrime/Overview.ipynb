{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chicago crime exploratory data analysis:\n",
    "The motivation behind this analysis is to understand and predict crime in the Chicago area. From 2010 to 2017 Chicago experienced 1,456,714 incidences of crime. For this analysis we'll focus on 2016 which saw 265,462 criminal occuances. From this study we'll be looking only at thefts in 2016 (the most common type of crime in the most recent year with data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"theft_chicago_map.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the year we notice some seasonal trends with Summer months showing the most thefts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"crime_by_month.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the counts of theft for each day in the year we see the same seasonal trend, as well as weekly periodic trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"crime_by_day.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few observations about crime we've made by looking through the data:\n",
    "+ Worse in the Summer than the rest of the year.\n",
    "+ Happens more on the weekend than during the week.\n",
    "+ Worst in the downtown areas.\n",
    "\n",
    "More can be found in the EDA notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling:\n",
    "To start modeling we'll look at physical features in Chicago and use them as inputs to machine learning algorithms. I've collected seven additional data sets from https://data.cityofchicago.org/.\n",
    "+ Vacant Lots\n",
    "+ Health Clinics\n",
    "+ Connect (internet access and tech training)\n",
    "+ Bus Stops\n",
    "+ Train Stations\n",
    "+ Farmers Markets\n",
    "+ Police Stations\n",
    "\n",
    "Each data set contains latitude and longitude values. Since these are discrete values and we need continuous for the algorithms, we'll use kernel density estimation (KDE) to drop a gaussian distribution at each point to create a sphere of influence around that observation. This is done for all the features and the response variables.\n",
    "In the following plots, the x and y axes correlate to latitude and longitude for a particular observation of a feature, and the deeper coloration indicates a higher value, or influence of the observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Bus Stops.png\"><img src=\"Police Stations.png\"><img src=\"Crimes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of the values we'll want to predict, we can remove the spatial aspect of the above graphs and just represent them as histograms. Below are the histograms for the test/training response variable and representing the distribution of values found in the crimes plot directly above. \n",
    "<img src=\"testTrainHist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of our feature vectors are as follows:\n",
    "<img src=\"featureHist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ML and Models notebook we build a baseline model for comparison to other standard ML models. One of the best performing models is the Decision Tree. By tuning the depth parameter from 2 to 5, to eventually 10, we're able to see improvements in the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dTreeTrainingError.png\">\n",
    "<img src=\"dTreeTrainingR2.png\">\n",
    "<img src=\"dTreeTestError.png\">\n",
    "<img src=\"dTreeTestR2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huge improvements when going from a depth of 2 to 5. With a depth of 10 we start to see values pretty close to perfect -- r-squared almost 1, and error approaching 0 -- which could signify overfitting, a common issue with decision trees. In the ML and Modeling notebook we try a few more complicated models, including boosting which is more resistant to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boosting algorithm returned the best results out of the ensemble methods, but we have to think carefully about the results we're getting. So far we've been dealing with values in a continuous space. In reality we want binary values representing if there is crime or not. Essentially we're turning our predicted threat model into a binary space representing where the model expects crime to happen. Then we can compare that with the week of actual crime data following our training/test week. By making this change we've turned this into a classification problem, and as a classification problem, we can check its performance with a ROC curve.  \n",
    "<img src=\"roc.png\">\n",
    "Ideally we'd like to see a true positive rate (sensitivity -- which is represented on the y axis), increase early and remain high as the false positive rate (specificity) increases. As it stands now we see both sensitivity and specificity increasing at the same rate, which indicates that our model isn't doing better than random guessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Our goal with this analysis was to gain some understanding of crime in the Chicago area and attempt to predict future crimes. To that end we've done the following:\n",
    "+ Collected data on crimes and geospatial features in Chicago.\n",
    "+ Converted the single point spatial data into a continuous problem space. \n",
    "+ Applied various machine learning algorithms to predict high density crime areas, and compared those areas to real crime data.\n",
    "\n",
    "Unfortunately, our results didn't lead to any <a href=\"http://www.imdb.com/title/tt0181689/\">Minority Report</a> style crime detection. There are few things learned during this process that would be helpful for future iterations:\n",
    "+ In the exploratory data analysis, one of the big takeaways was that crime had a periodic nature. We saw an overall increase in the summer months as well as higher rates during the weekends. This wasn't really taken into account in the models. \n",
    "+ Instead of using a week as a single block of time, varying the scope of the training/testing data would be interesting and possibly help with the weekend spike in crime.\n",
    "+ In additional to static spatial features like bus stops and police stations, including events such as music festivals and sports games would be valuable. They're already common targets for thieves, and mostly fall on weekends."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
